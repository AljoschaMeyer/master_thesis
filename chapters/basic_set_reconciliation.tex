% !TEX root = ../main.tex

In this chapter, we consider the set reconciliation protocol sketched in the introduction in greater detail.
We define the protocol in \cref{set-reconciliation-def}, prove its correctness in \cref{set-reconciliation-simple-correct}, and do a complexity analysis in \cref{set-reconciliation-complexity}.  \Cref{set-reconciliation-simple-optimizations} lists some optimizations which do not change the asymptotic complexity but which avoid some unnecessary work. We conclude the chapter with an example application in \cref{set-reconciliation-graphs}, briefly describing how the protocol can be applied to the synchronization of the hash graphs that arise e.g. in the context of distributed version control systems such as git~\cite{chacon2014pro}.

\section{Recursive Set Reconciliation}
\label{set-reconciliation-def}

The set reconciliation protocol assumes that there is a set $U$, a linear order $\preceq$ on $U$, a node $\mathcal{X}_0$ locally holding some $X_0 \subseteq U$, and a node $\mathcal{X}_1$ locally holding $X_1 \subseteq U$. Both nodes are able to compute fingerprints for sets via some function $\fun{\fpname}{\powerset{U}}{D}$. This function could in principle be any hash function, but in the complexity analysis we will assume that it is instantiated as $\lift{\f}{\mathcal{M}}$ with a suitable underlying hash function $f$ and a suitable monoid $\mathcal{M}$ over the universe $D$ (see \cref{def-lift}).

Recall that $\interval{x}{y}{S}$ denotes the set $\set{s \in S \mid x \preceq s \prec y}$ if $x \prec y$, or $S \setminus \interval{y}{x}{S}$ if $y \preceq x$ (\cref{def-interval}).

$\mathcal{X}_0$ and $\mathcal{X}_1$ exchange messages over multiple rounds, a message consists of an arbitrary number of \defined{interval fingerprints} and \defined{interval item sets}.
An interval fingerprint is a triple $\ifp{x}{y}{X_i}$ for $x, y \in U$, an interval item set a four-tuple $\iis{x}{y}{S}{b}$ for $x, y \in U$, $S \subseteq \interval{x}{y}{X_i}$, and $b \in \{0, 1\}$. $b$ indicates whether the interval item set is a response to a previous interval item set.

When a node $\mathcal{X}_i$ receives a message, it performs the following actions:

\begin{itemize}
  \item For every interval item set $\iis{x}{y}{S}{b}$ in the message, all items in $S$ are added to the locally stored set $X_i$. If $b = 0$, the node then adds the interval item set $\iis{x}{y}{\interval{x}{y}{X_i} \setminus S}{1}$ to the response, unless $\interval{x}{y}{X_i} \setminus S = \emptyset$.
  \item For every interval fingerprint $\ifp{x}{y}{X_j}$ in the message, it does one of following:
    \begin{caselist}
      \case[Equal Fingerprints] \label{def-fingerprint-eq} If $\fp{\interval{x}{y}{X_j}} = \fp{\interval{x}{y}{X_i}}$, nothing happens.
      \case[Recursion Anchor] \label{def-recursion-anchor} The node may add the interval item set $\iisnatural{x}{y}{X_i}{0}$ to the response. If $\abs{\interval{x}{y}{X_j}} \leq 1$, it must do so.
      \case[Recurse] \label{def-recurse} Otherwise, the node selects $m_0 = x \prec m_1 \prec \ldots \prec m_k = y \in U$, $k \geq 2$ such that among all $\interval{m_0}{m_1}{X_i}$ for  $0 \leq l < k$ at least two intervals are non-empty. For all $0 \leq l < k$ it adds either the interval fingerprint $\ifp{m_l}{m_{l + 1}}{X_i}$ or the interval item set $\iisnatural{m_l}{m_{l + 1}}{X_i}{0}$ to the response.
    \end{caselist}
  \item If the accumulated response is nonempty, it is sent to the other node. Otherwise, the protocol has terminated successfully.
\end{itemize}

To initiate reconciliation of an interval $[x, y)$, a node $\mathcal{X}_i$ sends a message containing solely the interval fingerprint $\ifp{x}{y}{X_i}$.

\Cref{simple-set-reconciliation-example} gives an example run of the protocol.

\begin{figure*}
$X_0 \defeq \{\exampleb, \examplec, \exampled, \examplee, \examplef, \exampleh \}$
\hfill
$X_1 \defeq \{\examplea, \examplee, \examplef, \exampleg\}$

\begin{scaletikzpicturetowidth}{\textwidth}
\begin{tikzpicture}[scale=\tikzscale, font=\tiny]
	\pgfdeclarelayer{background}
	\pgfdeclarelayer{foreground}
	\pgfsetlayers{background,main,foreground}
	
	\begin{pgfonlayer}{main}
		%vertices
		\node (vroot) at (0, 1) [fpi] {\examplefpi{\examplea}{\examplei}{\{\examplea, \examplee, \examplef, \exampleg\}}};

		\node (v00) at (-4, -0) [fpi] {\examplefpi{\examplea}{\examplee}{\{\exampleb, \examplec, \exampled\}}};
		\node (v01) at (4, -0) [fpi] {\examplefpi{\examplee}{\examplei}{\{\examplee, \examplef, \exampleh\}}};

                \node (v10) at (-4, -1) [iis] {\exampleiis{\examplea}{\examplee}{\{\examplea\}}{0}};
                \node (v11) at (2, -1) [fpi] {\examplefpi{\examplee}{\exampleg}{\{\examplee, \examplef\}}};
                \node (v12) at (6, -1) [iis] {\exampleiis{\exampleg}{\examplei}{\{\exampleg\}}{0}};

                \node (v20) at (-4, -2) [iis] {\exampleiis{\examplea}{\examplee}{\{\exampleb, \examplec, \exampled\}}{1}};
                \node (v21) at (6, -2) [iis] {\exampleiis{\exampleg}{\examplei}{\{\exampleh\}}{1}};
		%edges
                \draw (vroot) edge[edge] (v00);
                \draw (vroot) edge[edge] (v01);

		\draw (v00) edge[edge] (v10);
		\draw (v01) edge[edge] (v11);
		\draw (v01) edge[edge] (v12);

		\draw (v10) edge[edge] (v20);
		\draw (v12) edge[edge] (v21);
	\end{pgfonlayer}
	
	\begin{pgfonlayer}{background}
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, 1) -- (-8, 1);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](-8, -0) -- (8, -0);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, -1) -- (-8, -1);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](-8, -2) -- (8, -2);
	\end{pgfonlayer}
\end{tikzpicture}
\end{scaletikzpicturetowidth}

\caption{
An example run of the protocol. $\mathcal{X}_1$ initiates reconciliation for all items between \examplea~ and \examplei (ordered alphabetically) by sending its fingerprint for the whole interval.
Upon receiving this interval fingerprint, $\mathcal{X}_0$ locally computes $\fp{\interval{\examplea}{\examplei}{X_0}}$. Since the result does not match the received interval, $\mathcal{X}_0$ splits $X_0$ into two parts of equal size and transmits interval fingerprints for these subintervals.
In the third round, $\mathcal{X}_1$ locally computes fingerprints for the two received intervals, but neither matches. $\abs{\interval{\examplea}{\examplee}{X_1}} \leq 1$, so $\mathcal{X}_1$ transmits the corresponding interval items set, i.e. $\iis{\examplea}{\examplee}{\examplea}{0}$. $\abs{\interval{\examplee}{\examplei}{X_1}} > 1$, so another recursion step is performed. After splitting the interval, the lower interval is large enough to send its fingerprint, the upper one however only contains one item and thus results in another interval item set.
In the fourth and final communication round, $\mathcal{X}_0$ receives two interval item sets and answers with the items it holds within those intervals. When it receives the interval fingerprint $\ifp{\examplee}{\exampleg}{X_1}$, it computes an equal fingerprint for $\ifp{\examplee}{\exampleg}{X_0}$, so no further action is required for this particular interval. TODO prettify this caption
}

\label{simple-set-reconciliation-example}
\end{figure*}

\subsection{Observations}
\label{observations}

Partitioning based on a total order allows the nodes to perform a limited form of queries, i.e. range queries. A node can ask for reconciliation within a certain interval, rather than over the whole universe.

If the universe $U$ is not finite, then there are items that require an arbitrary amount of bytes to encode. Since the protocol needs to transmit items to denote interval boundaries, no reasonably complexity guarantees can be given for infinite universes. We will thus assume $U$ to be finite and small enough that items can be reasonably encoded. This assumption is not very restrictive in practice because nodes can always synchronize hashes of items rather than the items themselves. The protocol can then be either followed by a phase where hashes of interest are transferred and anwered by the actual items, or the protocol can be made aware of the distinction and use hashes as interval boundaries while transmitting actual items for interval item sets.

When reconciling hashes in place of actual items, any semantically interesting order on the items would be replaced by an arbitrary order on the hashes. But rather than using only's the hashes as interval boundaries, one can just as well add additional information. For example if the universe of interest consists of timestamped strings of arbitrary length, the interval boundaries can consist of timestamped hashes, ordered by timestamp first and using the numeric order on the hashes as a tiebreaker. \Cref{set-reconciliation-graphs} gives a more detailed example for utilizing this technique.

\section{Proof of Correctness}
\label{set-reconciliation-simple-correct}

\newcommand{\intcount}[1]{\mathit{count}_{#1}}

We now prove the correctness of the protocol. The protocol is correct if for all $x, y \in U$ both nodes eventually hold $\interval{x}{y}{X_i} \cup \interval{x}{y}{X_j}$ after a node $\mathcal{X}_i$ has received a message pertaining to the interval $[x, y)$.

\begin{caselist}
\case[Interval Item Set] \label{case-iis}  If the message contains the interval item set $\iisnatural{x}{y}{X_j}{0}$, then $\mathcal{X}_i$ adds all items to its set, resulting in $\interval{x}{y}{X_i} \cup \interval{x}{y}{X_j}$ as desired. $\mathcal{X}_j$ then receives $\iis{x}{y}{\interval{x}{y}{X_i} \setminus \interval{x}{y}{X_j}}{1}$, ending up with $\interval{x}{y}{X_j} \cup (\interval{x}{y}{X_i} \setminus \interval{x}{y}{X_j}) = \interval{x}{y}{X_i} \cup \interval{x}{y}{X_j}$ as desired.

\case[Interval Fingerprint] \label{case-ifp} Otherwise, the message contains an interval fingerprint $\ifp{x}{y}{X_j}$.

\begin{caselist}
\case[Equal Fingerprints] If $\fp{\interval{x}{y}{X_j}} = \fp{\interval{x}{y}{X_i}}$, the protocol terminates immediately and no changes are performed by any node. Assuming no fingerprint collision occurred, $\interval{x}{y}{X_i} = \interval{x}{y}{X_j} = \interval{x}{y}{X_i} \cup \interval{x}{y}{X_j}$ as desired.

\case[Recursion Anchor] \label{case-ifp-anchor} If $\mathcal{X}_i$ adds the interval item set $\iisnatural{x}{y}{X_i}{0}$, then \cref{case-iis} applies when the other node receives the response, with the roles reversed.

\case[Recurse] Let $\intcount{i} \defeq \abs{\interval{x}{y}{X_i}}$ and $\intcount{j} \defeq \abs{\interval{x}{y}{X_j}}$. $\intcount{j} \geq 2$, since otherwise $\mathcal{X}_j$ would have sent an item set for the interval. Similarly, $\intcount{i} \geq 2$, since we are not in \cref{case-ifp-anchor}. Thus, $\intcount{i} + \intcount{j} \geq 4$, and the protocol has already been proven correct for all cases where $\intcount{i} + \intcount{j} < 4$. 

We can thus finish the proof by induction on $\intcount{i} + \intcount{j}$, using the induction hypothesis that for all $x', y' \in U$ such that $\abs{\interval{x'}{y'}{X_i}} + \abs{\interval{x'}{y'}{X_j}} < \intcount{i} + \intcount{j}$ the protocol correctly reconciles $\interval{x'}{y'}{X_i}$ and $\interval{x'}{y'}{X_j}$.

$\mathcal{X}_i$ partitions the interval into $k \geq 2$ subintervals, of which at least two must be nonempty.
Thus $\abs{\interval{m_l}{m_{l + 1}}{X_i}} < \intcount{i}$ for all $0 \leq l < k$.
Furthermore, $\interval{m_l}{m_{l + 1}}{X_j} \subseteq \interval{x}{y}{X_j}$ and thus $\abs{\interval{m_l}{m_{l + 1}}{X_j}} \leq \abs{\interval{x}{y}{X_j}}$, so overall we have $\abs{\interval{m_l}{m_{l + 1}}{X_i}} + \abs{\interval{m_l}{m_{l + 1}}{X_j}} < \intcount{i} + \intcount{j}$ and can apply the induction hypothesis to conclude that every subinterval is correctly reconciled. Since the subintervals partition the original interval, the original interval is then correctly reconciled as well.
\end{caselist}
\end{caselist}

\section{Complexity Analysis}
\label{set-reconciliation-complexity}

The protocol gives nodes the freedom to respond to an interval fingerprint with an interval item set even if the interval fingerprint is arbitrarily large. For a meaningful complexity analysis we need to restrict the behavior of the node, a realistic modus operandi is for a node to send an interval item set whenever it holds a number of items less than or equal to some threshold $t \in \mathbb{N}, t \geq 1$ within the interval. Higher choices for $t$ reduce the number of roundtrips, but increase the probability that a items is being sent even though the other node already holds it.

A node is similarly given freedom over the number of subintervals into which to split an interval when recursing. We will assume a node always splits into at most $b \in \mathbb{N}, b \geq 2$ subintervals. As with $t$, higher numbers reduce the number of roundtrips at the cost of potentially sending items or fingerprints that did not need sending.

Because we want to analyze not only the worst-case complexity but also the complexity depending on the similarity between the two sets held by the participating nodes, we define some rather fine-grained instance size parameters: $n_0$ and $n_1$ denote the number of items held by $\mathcal{X}_0$ and $\mathcal{X}_1$ respectively. We let $n \defeq n_0 + n_1$, $n_{\min} \defeq \min(n_0, n_1)$, $n_{\max} \defeq \max(n_0, n_1)$, $n_{\cap} \def \abs{\interval{x}{y}{X_0} \cap \interval{x}{y}{X_1}}$, $n_{\cup} \def \abs{\interval{x}{y}{X_0} \cup \interval{x}{y}{X_1}}$ and $n_{\triangle} \defeq \abs{(\interval{x}{y}{X_0} \cup \interval{x}{y}{X_1}) \setminus (\interval{x}{y}{X_0} \cap \interval{x}{y}{X_1})}$. TODO remove those that are not needed

\subsection{Preliminary Observations}

A helpful observation for the following analysis is that the interval fingerprints that are being exchanged during a protocol run form a rooted tree where every vertex has at most $b$ children. When a leaf of the tree is reached, an exchange of interval item sets follows. Equal fingerprints can also cut the tree short, but for the following worst-case analyses we will assume this does not occur.

Node $\mathcal{X}_i$ can branch at most $\ceil{\log_{b}(n_i)}$ times, so the overall height of the tree is bounded by $2 \cdot\ceil{\log_{b}(n_{\min})}$. The number of vertices of such a complete tree of height $h$ is at most $\sum_{i=0}^{h} b^{i} = \frac{b^{h} - 1}{b - 1}$. For $h \leq 2 \cdot\ceil{\log_{b}(n_{\min})}$, $\frac{b^{h} - 1}{b - 1} \leq 2 \cdot 2 \cdot n_{\min} \leq 2n \in \complexity{n}$.

The parameter $t$ determines when recursion is cut off, and thus influences the height of the tree. For $t = 1$, the protocol recurses as far as possible. For $t = b$, the last level of recursion is cut off, for $t = b^2$ the last two levels, and so on. Overall, the height of the tree is reduced by $\floor{\log_{b}(t)}$.

\subsection{Communication Rounds}

The number of communication rounds clearly corresponds to the height of the tree, plus $2$ to account for the exchange of interval item sets, so the worst-case is $2 + 2 \cdot\ceil{\log_{b}(n_{\min})} - \floor{\log_{b}(t)} \in \complexity{\log_{b}(n)}$. This number cannot be bounded by $n_{\triangle}$, as witnessed by problem instances where one node is missing exactly one item compared to the other node. In such an instance, $b - 1$ branches in each recursion step result in equal fingerprints, but the one branch that does continue reaches the recursion anchor only after the full number of rounds. See \cref{fig:worst-rounds} for an example.

\begin{figure*}
$X_0 \defeq \{\examplea, \exampleb, \examplec, \exampled, \examplee, \exampleg, \exampleh \}$
\hfill
$X_1 \defeq \{\examplea, \exampleb, \examplec, \exampled, \examplee, \examplef, \exampleg, \exampleh \}$

\begin{scaletikzpicturetowidth}{\textwidth}
\begin{tikzpicture}[scale=\tikzscale, font=\tiny]
	\pgfdeclarelayer{background}
	\pgfdeclarelayer{foreground}
	\pgfsetlayers{background,main,foreground}
	
	\begin{pgfonlayer}{main}
		%vertices
		\node (vroot) at (0, 1) [fpi] {\examplefpi{\examplea}{\examplei}{\{\examplea, \exampleb, \examplec, \exampled, \examplee, \examplef, \exampleg, \exampleh\}}};

		\node (v00) at (-4, -0) [fpi] {\examplefpi{\examplea}{\examplee}{\{\examplea, \exampleb, \examplec, \exampled\}}};
		\node (v01) at (4, -0) [fpi] {\examplefpi{\examplee}{\examplei}{\{\examplee, \exampleg, \exampleh\}}};

                \node (v10) at (2, -1) [fpi] {\examplefpi{\examplee}{\exampleg}{\{\examplee, \examplef\}}};
                \node (v11) at (6, -1) [fpi] {\examplefpi{\exampleg}{\examplei}{\{\exampleg, \exampleh\}}};

                \node (v20) at (2, -2) [iis] {\exampleiis{\examplee}{\exampleg}{\{\examplee\}}{0}};

                \node (v30) at (2, -3) [iis] {\exampleiis{\examplee}{\exampleg}{\{\examplef\}}{1}};

		%edges
                \draw (vroot) edge[edge] (v00);
                \draw (vroot) edge[edge] (v01);

		\draw (v01) edge[edge] (v10);
		\draw (v01) edge[edge] (v11);

		\draw (v10) edge[edge] (v20);
		
		\draw (v20) edge[edge] (v30);
	\end{pgfonlayer}
	
	\begin{pgfonlayer}{background}
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, 1) -- (-8, 1);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](-8, -0) -- (8, -0);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, -1) -- (-8, -1);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](-8, -2) -- (8, -2);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, -3) -- (-8, -3);
	\end{pgfonlayer}
\end{tikzpicture}
\end{scaletikzpicturetowidth}

\caption{An example run of the protocol that takes the greatest possible number of rounds even though $n_{\triangle} = 1$. $b \defeq 2, t \defeq 1$.}

\label{fig:worst-rounds}

\end{figure*}

\subsection{Communication Complexity}
\label{communication-complexity}

The total number of bits that needs to be transmitted during a protocol run is proportional to the number of vertices in the tree. Every interval fingerprint consists of two items and one fingerprint, so assuming $U$ is finite this lies in $\complexity{1}$. Since there are at most $2n$ vertices in the tree, the interval fingerprints require at most $\complexity{n}$ bits to be communicated.

The exchange of interval item sets consists in the worst case of exchanging every item using $\ceil{\frac{n}{t}}$ interval item sets. An interval item set needs to transmit two items to encode the boundaries, as well as the items themselves, which lies in $\complexity{1}$ per interval item set. All interval item sets together thus amount to another $\complexity{n}$, leading to a total of $\complexity{n}$ bits being transmitted in the worst case.

\Cref{fig:worst-bytes} shows a worst-case example in which the tree of height $h \defeq \log_{b}(2 \cdot n_{\min})$ has all $\frac{b^{h} - 1}{b - 1}$ vertices.

\begin{figure*}
$X_0 \defeq \{\examplea, \examplec, \examplee, \exampleg \}$
\hfill
$X_1 \defeq \{\examplea, \exampleb, \examplec, \exampled, \examplee, \examplef, \exampleg, \exampleh\}$

\begin{scaletikzpicturetowidth}{\textwidth}
\begin{tikzpicture}[scale=\tikzscale, font=\tiny]
	\pgfdeclarelayer{background}
	\pgfdeclarelayer{foreground}
	\pgfsetlayers{background,main,foreground}
	
	\begin{pgfonlayer}{main}
		%vertices
		\node (vroot) at (0, 1) [fpi] {\examplefpi{\examplea}{\examplei}{\{\examplea, \exampleb, \examplec, \exampled, \examplee, \examplef, \exampleg, \exampleh\}}};

		\node (v00) at (-4, -0) [fpi] {\examplefpi{\examplea}{\examplee}{\{\examplea, \examplec\}}};
		\node (v01) at (4, -0) [fpi] {\examplefpi{\examplee}{\examplei}{\{\examplee, \exampleg\}}};

                \node (v10) at (-6, -1) [fpi] {\examplefpi{\examplea}{\examplec}{\{\examplea, \exampleb\}}};
                \node (v11) at (-2, -1) [fpi] {\examplefpi{\examplec}{\examplee}{\{\examplec, \exampled\}}};
                \node (v12) at (2, -1) [fpi] {\examplefpi{\examplee}{\exampleg}{\{\examplee, \examplef\}}};
                \node (v13) at (6, -1) [fpi] {\examplefpi{\exampleg}{\examplei}{\{\exampleg, \exampleh\}}};

                \node (v20) at (-6, -2) [iis] {\exampleiis{\examplea}{\examplec}{\{\examplea\}}{0}};
                \node (v21) at (-2, -2) [iis] {\exampleiis{\examplec}{\examplee}{\{\examplec\}}{0}};
                \node (v22) at (2, -2) [iis] {\exampleiis{\examplee}{\exampleg}{\{\examplee\}}{0}};
                \node (v23) at (6, -2) [iis] {\exampleiis{\exampleg}{\examplei}{\{\exampleg\}}{0}};

                \node (v30) at (-6, -3) [iis] {\exampleiis{\examplea}{\examplec}{\{\exampleb\}}{1}};
                \node (v31) at (-2, -3) [iis] {\exampleiis{\examplec}{\examplee}{\{\exampled\}}{1}};
                \node (v32) at (2, -3) [iis] {\exampleiis{\examplee}{\exampleg}{\{\examplef\}}{1}};
                \node (v33) at (6, -3) [iis] {\exampleiis{\exampleg}{\examplei}{\{\exampleh\}}{1}};
		%edges
                \draw (vroot) edge[edge] (v00);
                \draw (vroot) edge[edge] (v01);

		\draw (v00) edge[edge] (v10);
		\draw (v00) edge[edge] (v11);
		\draw (v01) edge[edge] (v12);
		\draw (v01) edge[edge] (v13);

		\draw (v10) edge[edge] (v20);
		\draw (v11) edge[edge] (v21);
		\draw (v12) edge[edge] (v22);
		\draw (v13) edge[edge] (v23);

		\draw (v20) edge[edge] (v30);
		\draw (v21) edge[edge] (v31);
		\draw (v22) edge[edge] (v32);
		\draw (v23) edge[edge] (v33);
	\end{pgfonlayer}
	
	\begin{pgfonlayer}{background}
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, 1) -- (-8, 1);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](-8, -0) -- (8, -0);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, -1) -- (-8, -1);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](-8, -2) -- (8, -2);
		\draw[-{Triangle[width=30pt,length=17pt,color=gray]}, line width=15pt, color=gray](8, -3) -- (-8, -3);
	\end{pgfonlayer}
\end{tikzpicture}
\end{scaletikzpicturetowidth}

\caption{An example run of the protocol that requires transmitting the maximum amount of bytes. $b \defeq 2, t \defeq 1$.}

\label{fig:worst-bytes}
\end{figure*}

This worst-case complexity is no better than the naïve protocol where the two nodes simply exchange their whole item sets. The motivation behind our protocol is to utilize similarities in the sets that are being reconciled, so it it makes sense to bound the communication complexity by $n_{\triangle}$.

As discussed in the analysis of the number of communication rounds, if $n_{\triangle} = 1$ this results in the protocol tracing a path from the root to a leaf in the tree. If $n_{\triangle}$ takes on larger values, more paths from the root to leaves occur, each contributing up to $2 + 2 \cdot\ceil{\log_{b}(n_{\min})} - \floor{\log_{b}(t)} \in \complexity{\log_{b}(n)}$ vertices, but the number of vertices in the union of these paths is of course bounded by the total number of vertices in the tree. We thus obtain a communication complexity of $\complexity{\min(n_{\triangle} \cdot \log_b(n), n)}$ bits.

\subsection{Impact of Randomized Interval Boundaries}
\label{random-boundaries}

\Cref{why-random-boundaries} argues in favor of randomizing interval boundaries to protect against the impact of maliciously crafted fingerprint collisions. We now consider three different randomization strategies and their impacts on the number of communication rounds and the number of bits that need to be transmitted. To describe the boundary selection strategies, first consider that splitting an ordered set $S = \set{s_0 \prec s_1 \prec \ldots \prec s_{n - 1}}$ items into $b$ intervals consists of choosing $b$ indices $i_0 < i_1 < \ldots < i_{b-1}$, thus defining the intervals $\interval{s_{i_0}}{s_{i_1}}{S}, \interval{s_{i_1}}{s_{i_2}}{S}, \ldots, \interval{s_{i_{b - 2}}}{s_{i_{b - 1}}}{S}, \interval{s_{i_{b - 1}}}{s_{i_0}}{S}$.

The randomization strategy with the lowest impact creates intervals of identical sizes as the regular strategy (splitting into $b$ subintervals of evenly distributed size per communication around), but shifts where these boundaries lie. Precisely: first, interval boundaries $i_0, i_1, \ldots, i_{b - 1}$ are computed deterministically, all of which lie $\frac{n}{b}$ apart. Then some random integer $k \in \interval{0}{\frac{n}{b}}{\N}$ is chosen, and then the new boundaries are $s_{i_j + k \mod b}$ for all $0 \leq j < b$.

 As the number and size of intervals is identical to that of the deterministic protocol version, communication complexity remains unchanged. Yet there are $\frac{n}{b}$ different possible partions of an interval of size $n$, thus reducing the probability that a particular maliciously crafted fingerprint collision affects a given communication round by that factor.

In order to minimize the probability that a collision affects a protocol run, interval boundaries can be chosen fully at random, for a total of $\binom{n}{b}$ possible outcomes. The worst-case number of communication rounds occurs when in every round $b-1$ of the interval contain exactly one item and the last interval contains all the remaining items, leading to $\frac{n}{b - 1}$ rounds. The expected number of rounds is however still $\complexity{\log_b(n)}$ with high probability, as it corresponds to the height of a randomly chosen $b$-complete tree, which is expected $\complexity{\log_b(n)}$~\cite{devroye1990height}.

A simple way of recovering a logarithmic worst-case round number while keeping the number of possible partions super-linear is to choose the boundaries randomly within equally sized regions of the interval: choose $i_j$ randomly from $\interval{j \cdot \frac{n}{b}}{(j + 1) \cdot \frac{n}{b}}{\N}$ (and take $i_{b - 1}$ modulo $n$ if necessary). The number of possible outcomes is $(\frac{n}{b})^b \in \complexity{n^b}$. Since any interval obtained this way can contain most $2b$ items, the worst-case number of communication rounds is $\complexity{\log_{\frac{b}{2}}(n)}$.

\subsection{Computational Complexity}

We now analyze the computational cost incurred by a single communication round, i.e. computing the response to a message. This includes both fingerprint comparisons as well as locating the items to transmit. We do however assume that an auxiliary data structure is available to help with this computation, e.g. the a fingerprint tree structure presented in \cref{group-fingerprints}. We exclude both space usage and maintenance cost for this data structure from the per-round complexity.

We will assume that transferring an item as part of an interval item set requires $\complexity{1}$ time and space. The relevant computational overhead per communication round thus consists of computing $\fp{\interval{x}{y}{X_i}}$ for every received interval fingerprint $\ifp{x}{y}{X_j}$, as well as partitioning $\interval{x}{y}{X_i}$ in case of a mismatch and computing the fingerprints over all subintervals. These computations can be performed independently for all received interval fingerprints, so in particular they can be performed sequentially, reusing space. The overall space complexity of the per-round computations is equal to that of the computations for a single interval fingerprint.

We first address the problem of partitioning intervals. After the indices of the boundaries have been determined as described in the previous section, how can they be efficiently translated into actual items? This can be accomplished by augmenting the auxiliary tree structure by storing in each vertex $v$ the number of vertices in $T_v$. With this information, one can efficiently traverse the tree based on relative offsets on the number of items to traverse.

The problem thus consists of computing $k \cdot (b + 1)$ fingerprints in the worst case, where $k$ is the number of interval fingerprints that have been received - one fingerprint computation per received fingerprint to compare the received fingerprint with the local one, and then $b$ further ones for splitting the interval.

A naive approach is to query the auxiliary data structure for each fingerprint to compute individually. The maximum amount of queries is upper-bounded by $n$, as $n$ items cannot be split into more than $n$ non-empty intervals. Unfortunately, the greatest possible number of interval fingerprints within a single round corresponds to the number of leaves in the recursion tree, which is in $\complexity{n}$. The auxiliary data structure requires $\complexity{\log(n)}$ time per query, leading to an overall time complexity of $\complexity{n \cdot \log(n)}$.

In the next section, by doing a smarter traversal of the auxiliary tree, we can bring this down to $\complexity{\min(\log(n), n)}$ time while staying in $\complexity{1}$ space usage for fingerprints based on a group operation.

\section{Bulk Fingerprint Computation}

The two main components of efficiently computing fingerprints for multiple, successive intervals are doing a traversal of the auxiliary tree with a linear bound on the number of traversed edges, and the computation of fingerprints based on the data encountered in this traversal.

\subsection{Tree Traversal}

We express the tree traversal as a function which takes as arguments the vertex at which to start and the vertex to seek, and returns this vertex, or \texttt{Nothing} if it is not in the tree. Since any particular vertex might be reached multiple times during a traversel, an additional argument specifies the direction in which to search: either a vertex is reached from its parent with the goal of exploring into the subtree rooted at the vertex, or a vertex is reached from one of its children, with the goal of continuing the search outside the subtree that was just left. Ultimately, this is a generalization of the usual function for finding an element in a search tree, allowing to specify an arbitrary starting vertex rather than always beginning in the root.

To allow upward traversal in the tree, we store in each vertex a reference to its parent, if one exists. As usual, we restrict the presentation of algorithms to complete binary trees.

\begin{minted}[mathescape]{haskell}
-- Last member this the parent pointer.
data Node = Leaf U D (Maybe Node) | Inner Node U Node D (Maybe Node)

-- Extract the parent pointer of a node.
getParent :: Node -> Maybe Node
getParent Leaf _ _ p     = p
getParent Inner _ _ _ _ p = p

-- Extract the item of a node.
getItem:: Node -> U
getItem Leaf v _ _     = v
getItemInner _ v _ _ _ = v

data Direction = FromParent | FromLeftChild | FromRightChild

-- Return $\mathtt{Just FromLeftChild}$ and the parent if the given node is a left child,
-- $\mathtt{Just FromRightChild}$ and the parent if the given node is a right child,
-- and $\mathtt{Nothing}$ otherwise. Also returns the parent.
parentDirection :: Node -> Maybe (Direction, Node)
parentDirection v = case (getParent v) of
    Nothing -> Nothing
    Just p  -> if ((getItem v) < (getItem p))
        then (Just (FromLeftChild, p))
        else (Just (FromRightChild, p))

-- Search for the item $\mathtt{x}$ starting at node $\mathtt{src}$.
traverse :: Node -> Direction -> U -> (Maybe Node, Direction)
traverse src@(Leaf v d p) _ x
    | x <= v    = (Just src,  -- $\mathtt{src}$ is the least vertex with  $\mathtt{x} \preceq v$
    | otherwise = case (parentDirection src) of
        Nothing     -> (Nothing, FromRightChild) -- $\mathtt{x}$ greater than any item
        Just (direction, parent) -> traverse parent direction x -- continue search upwards
traverse src@(Inner l v r _ p) FromParent x
    | x < v  = traverse l FromParent x
    | x == v = (Just src, FromParent)
    | x > v  = traverse r FromParent x
traverse src@(Inner l v r _ p) FromLeftChild x
    | x <= v    = (Just src, FromParent)
    | otherwise = traverse r FromParent x
traverse src@(Inner l v r _ p) FromRightChild x = case (parentDirection src) of
    Nothing     -> (Nothing, FromRightChild) -- $\mathtt{x}$ greater than any item
    Just (direction, parent) -> traverse parent direction x -- continue search upwards
\end{minted}

\Cref{fig:traverse} gives an example of how the \texttt{traverse} function operates and can be used to visit multiple vertices in succession.


\newcommand{\traverse}[3]{\texttt{(traverse #1 #2 #3)}}
\newcommand{\mypair}[2]{\texttt{(#1, #2)}}
\tikzmath{\w = 0.5; \h = 0.4; \hi = 0.2; }

\begin{figure*}
\begin{scaletikzpicturetowidth}{\textwidth}
\begin{tikzpicture}[scale=\tikzscale]
	\pgfdeclarelayer{background}
	\pgfdeclarelayer{foreground}
	\pgfsetlayers{background,main,foreground}
	
	\begin{pgfonlayer}{main}
		%vertices
		\node (vroot) at (0, 1) [skiplistnode] {\exampled};

		\node (v00) at (-4, -1) [skiplistnode] {\exampleb};
		\node (v01) at (4, -1) [skiplistnode] {\exampleg};

                \node (v10) at (-6, -3) [skiplistnode] {\examplea};
                \node (v11) at (-2, -3) [skiplistnode] {\examplec};
                \node (v12) at (2, -3) [skiplistnode] {\examplee};
                \node (v13) at (6, -3) [skiplistnode] {\exampleh};
		%edges
                \draw [preaction={draw, line width=3pt, red, transform canvas={xshift=1cm}}](vroot) edge[edge] (v00);
                \draw (vroot) edge[edge] (v01);

		\draw (v00) edge[edge] (v10);
		\draw (v00) edge[edge] (v11);
		\draw (v01) edge[edge] (v12);
		\draw (v01) edge[edge] (v13);

\draw[->,blue,rounded corners,dashed,line width=0.7pt]
    ($(vroot) + (-\w,\h)$) --
    ($(v00) +(-\w,\h)$) --
    ($(v00) +(-\w,-\h)$) --
    ($(v11) +(-\w,-\h)$) --
    ($(v11) +(\w,-\h)$);

\draw[->,green,rounded corners,dashed,line width=0.7pt]
    ($(v11) +(\w,-\h)$) --
    ($(v11) +(\w,\h)$) --
    ($(v00) +(\w,-\hi)$) --
    ($(v00) +(\w,0)$) --
    ($(vroot) +(-\w,-\h)$) --
    ($(vroot) +(\w,-\h)$) --
    ($(v01) +(-\w,0)$) --
    ($(v01) +(-\w,-\hi)$) --
    ($(v12) +(-\w,\h)$) --
    ($(v12) +(-\w,-\h)$) --
    ($(v12) +(\w,-\h)$) --
    ($(v01) +(0,-\h)$);

\draw[->,red,rounded corners,dashed,line width=0.7pt]
    ($(v01) +(0,-\h)$) --
    ($(v13) +(-\w,-\h)$) --
    ($(v13) +(\w,-\h)$) --
    ($(v13) +(\w,\h)$) --
    ($(v01) +(\w,\h)$) --
    ($(vroot) +(\w,\h)$);
	\end{pgfonlayer}
\end{tikzpicture}
\end{scaletikzpicturetowidth}

\begin{align*}
\traverse{\exampled}{FromParent}{\examplec} &= \traverse{\exampleb}{FromParent}{\examplec}\\
&= \mypair{Just \examplec}{FromParent}\\
\\
\traverse{\examplec}{FromParent}{\examplef} &= \traverse{\exampleb}{FromRightChild}{\examplef}\\
&= \traverse{\exampled}{FromLeftChild}{\examplef}\\
&= \traverse{\exampleg}{FromParent}{\examplef}\\
&= \traverse{\examplee}{FromParent}{\examplef}\\
&= \mypair{Just \exampleg}{FromLeftChild}\\
\\
\traverse{\exampleg}{FromLeftChild}{\exampley}&= \traverse{\exampleh}{FromParent}{\exampley}\\
&= \traverse{\exampleg}{FromRightChild}{\exampley}\\
&= \traverse{\exampled}{FromRightChild}{\exampley}\\
&= \mypair{Nothing}{FromRightChild}\\
\end{align*}
\caption{
Traversing a search tree: starting from the root, visiting \examplec\ (blue, found in the tree), \examplef\ (green, not in the tree, but finding the next greater item \exampleg), and \exampley\ (red, greater than any item in the tree) in succession.
}

\label{fig:traverse}
\end{figure*}

As this is a standard tree traversal independent from our fingerprint computations, we merely state the following observations without proof:

\begin{itemize}
\item Every edge is traversed at most two times, once in each direction.
\item Consequently, every vertex is visited at most once from its parent, and at most three times in total.
\item For $x, y \in U$ with $x \prec y$, the traversal from $x$ to $y$ in a tree on the item set $S$ takes at most $\complexity{\log_2(\abs{\interval{x}{y}{S}})}$ time.
\end{itemize}

As traversals take logarithmic time in the distance between the items, and successive traversals to successively greater items can overall visit any particular vertex at most a constant number of times, the time complexity for performing $k$ such traversals in a set of size $n$ is in $\complexity{\min(k \cdot \log(n), n)}$. The space complexity is in $\complexity{1}$, since the function is tail-recursive.

\subsection{Computing Fingerprints}

\section{Smaller Optimizations}
\label{set-reconciliation-simple-optimizations}

We now give a list of optimizations which do not impact the overall complexity analysis, but which do improve on some constant factors.

\subsection{Non-Uniform Partitions}

When partitioning an interval into subintervals, the protocol does not specify where exactly to place the boundaries. Splitting into partitions of roughly equal sizes makes a lot of sense if new data could arise anywhere within the linear order with equal probability. Is however the items are likely to fall within certain ranges of the order, it can be more efficient to use more fine-grained partitions within those regions. If for example items are sorted by timestamp, and new items are expected to be propagated to every node in the system within a couple of seconds, then all items older than ten seconds can be comfortably lumped together in a large interval.

\subsection{Subset Checks}
\label{subset-checks}

When a node $\mathcal{X}_i$ receives an interval fingerprint $\ifp{x}{y}{X_j}$, it might have a different fingerprint for that interval, but one of the resulting subintervals could match the received fingerprint. The node can then ignore that interval, transmitting only the remaining ones.

This scenario is a special case of receiving the fingerprint of a subset of the item one holds within an interval. In principle, a node can compute the fingerprints of arbitrary subsets of its interval, trying to find a match. If a match is found, the node knows that it holds a superset of the items the other node holds within the interval. The protocol could be extended with a message part that transmits items and does not warrant a response, this would be used to transmit $\interval{x}{y}{X_i} \setminus \interval{x}{y}{X_j}$.

Computing the fingerprint of all subsets of interval is infeasible since they are $2^n$ many subsets. As discussed in \cref{TODO} however, if the group operation for fingerprint computation is xor, a node can check whether the fingerprint of a subset of items matches a given fingerprint in $\complexity{n^3}$.
Assuming no fingerprint collisions occurred, checking whether a subset of $\interval{x}{y}{X_i}$ matches $\fp{\interval{x}{y}{X_j}}$ is equivalent to checking whether $\interval{x}{y}{X_i}$ is a superset of $\interval{x}{y}{X_j}$.

This leads to a protocol with a per-round computational complexity of $\complexity{n^3}$ TODO $n^4$? and the same worst-case guarantees, but which can skip recursive steps more often than the basic protocol. In particular, whenever two nodes reconcile where one of them holds a subset of the items of the other node, reconciliation terminates after at most three communication rounds.

TODO precomputation, see comment %https://piazza.com/class_profile/get_resource/jl30kcwntnn7f1/jlh5nh8gwuh11s

\subsection{Efficiently Encoding Intervals}

A naive encoding of interval fingerprints and interval item sets would transmit both boundaries of every interval, transmitting $2n$ items if there are $n$ intervals in a message. This can be brought down to $1 + n$ by utilizing that the lower boundary of all but the first interval it is also the upper boundary of the preceding one. An efficiently encoded message consists of the number of intervals it contains, followed by the lower boundary of the first interval, followed by pairs of interval information and the upper boundary of the interval that the information pertains to, where each \defined{interval information} is either a fingerprint, a set of items, or a dummy value signaling that this part of the overall interval is already fully synchronized.

The knowledge that interval boundaries are transmitted in ascending order can be used for compression. As a simple example, if interval boundaries are natural numbers, the upper boundaries can be transmitted as the difference to the previous boundary. This way, smaller numbers are transmitted, which admit shorter encodings. The same argument applies for transmitting sets of items in sorted order.

Note additionally that two adjacent interval item sets can be merged into a single one, saving on the transmission of the boundary between them.

\subsection{Utilizing Interval Boundaries}

Whenever the lower boundary of an interval is transmitted, an actual item is transmitted. If the receiving node knew whether the other node held this item, it would automatically be reconciled and could be excluded from further recursion steps. One way for achieving this is to tag each interval with a bit to indicate whether the lower boundary is being held by the sender. A different approach is to require that intervals are only split at items which the splitting node holds, this way no explicit bits needs to be transmitted, yet many boundaries can be identified as being held by the other node.

Recall that we assume $U$ to be finite. For $x \in U$ we can thus denote by $\successor{x}$ the necessarily unique $z \in U$ such that $x \prec z$ and there exists no $y \in U$ such that $x \prec y \prec z$ if a $z$ with $u \prec z$ exists, or $\min(U)$ otherwise. When sending or receiving an interval from $x$ to $y$ for which both nodes know that the sending node holds $x$, both nodes act as if the interval went from $\successor{x}$ to $y$, except that the receiving node adds $x$ to its local set of items.

\subsection{Multi-Level Fingerprints}

Since the protocol interprets equal interval fingerprints as both nodes holding the same set of items within the interval, but never verifies this merely probabilistic assumption, fingerprints need to be long enough to guarantee low collision probability. The longer the fingerprints, the more bits need to be transmitted however.

One can use smaller fingerprints if in case of equal fingerprints the nodes then exchange an additional fingerprint rather than immediately stopping the recursion for this interval. Whenever a node receives a first-level interval fingerprint that is equal to its own, it answers with the second-level fingerprint for the same interval. When a node receives a second-level interval fingerprint that is equal to its own, it terminates the recursion. If it is not equal, it recurses as usual, in particular it sends first-level fingerprints for any large subintervals.

This scheme can of course be extended to an arbitrary number of fingerprint levels. Every level increases the worst-case number of roundtrips by one, but decreases the average message size. If cryptographically secure fingerprints are desired, low levels of the fingerprint hierarchy do not have to be secure, only the top level fingerprint needs to be so. Alternatively, each fingerprint level can consist of some substring of a long, cryptographically secure fingerprint, such that the concatenation of these substrings yields the original fingerprint.

\section{Reconciling Hash Graphs}
\label{set-reconciliation-graphs}

In this section, we demonstrate how to apply the set reconciliation protocol the problem of reconciling hash graphs. Hash graphs arise in contexts where pieces of data refer to other pieces of data by a secure hash computed over the data to be referred to. Distributed version control systems such as git~\cite{chacon2014pro} for example represent the evolving contents of a directory as a set of deltas which describe how the contents changed from an earlier version, this earlier version is referenced as the hash of another such object. Some objects describe how to merge conflicting concurrent changes, these objects can reference multiple other objects. Since addressing uses a secure hash function, an object can only reference objects which existed prior to it. All in all, objects can thus form arbitrary directed, acyclic graphs (dags).

When two nodes wish to synchronize, they update each other's histories to the union of all objects known to both of them. This is a natural setting for the set reconciliation protocol. Since objects can become arbitrarily large, one would reconcile sets of hashes of these objects, and then a second stage request the actual objects for all newly obtained hashes.

This approach completely ignores the edges of the dag. While at first glance it might seem inefficient to ignore available structural information, the fact that the dags can take arbitrary shapes makes it hard to utilize the edge structure. The graphs might be dense or sparse, could contain arbitrarily large independent sets, paths, tournaments etc.

Even though arbitrary dags are possible and thus the logarithmically bounded worst-case complexity is important, one can in practice make some reasonable assumptions about the hash graphs arising from an average, version-controlled repository. It seems likely for example that most concurrent new work is performed relative to a rather recent state of the repository, whereas work based off a very old state is rather unlikely. We could hope for better average reconciliation times if the reconciliation algorithm leveraged this expectation.

To that end, rather than reconciling merely hashes of objects, we can reconcile pairs $(\mathit{depth}, \mathit{hash})$, sorting by depth first and hash second. The \defined{depth} of an object is the length of the longest path from that object to a root object, i.e. an object without predecessors. That is, the depth of an object is $1$ greater than the greatest depth of any predecessor object. If most concurrent work is based off similarly new state, then it also falls into a similar interval of the linear order. A protocol run does not need to recurse into intervals of low depth then, since no concurrently working peer produces new objects of low depth. If this assumption turns out to be wrong, the protocol nevertheless upholds its worst-case guarantee of a logarithmic number of communication rounds.

Another common scenario is that a node has not produced any new local objects and merely wants to catch up with the current state. Let $d$ be the maximal depth among all objects the node holds. Then rather than reconciling the interval $\interval{(0, 0)}{\top}{}$, the node can reconcile the interval $\interval{(0, 0)}{(d + 1, 0)}{}$ as well as sending an empty interval item set for the interval $\interval{(d + 1, 0)}{\top}{}$. All new changes of depth $d + 1$ or greater are then fetched in only two communication rounds. Any concurrent work (from a depth perspective) is reconciled as usual, and if all new changes are based off a recent version, the whole reconciliation process only takes a single round trip.