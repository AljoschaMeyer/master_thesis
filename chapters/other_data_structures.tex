% !TEX root = ../main.tex

In this chapter, we sketch some adaptations of the set reconciliation algorithm to related problems. \Cref{general-partitions} considers more general partitioning strategies than one-dimensional ranges. \Cref{maps} presents how to reconcile key-value mappings. \Cref{set-mirror} shows an asymmetric variant of the protocol, mirroring the contents of a set or map held at a primary node to a replica node. \Cref{authenticated} demonstrates how our data structures for fingerprint computations can also serve as simple authenticated data structures.

\section{Higher-Dimensional Ranges}
\label{general-partitions}

The set reconciliation algorithm recursively partitions the item sets of both nodes by splitting the sets into successive ranges. But for the correctness of the algorithm, the exact mechanism by which partitions are chosen is irrelevant. All that is necessary is that in each communication round, when receiving a mismatching fingerprint for some non-empty $S \subseteq U$, the node chooses a partition $\disjointunion{S_0}{\disjointunion{S_1}{\disjointunion{\ldots}{S_k}}} = S$ of $S$, and then communicates to the other node the choice of the partition and how its items are distributed among the individual sets.

Partitioning into successive ranges over a linearly ordered set has some nice properties: It can be applied to virtually any set since one can always arbitrarily define a linear order. The choice of the partition and the way the items are distributed among the sets can be encoded and transmitted efficiently. And finally, when receiving an arbitrarily chosen partition into successive ranges, a node can always efficiently compute the items it holds within that partition as well as the fingerprint over these items.

As long as nodes always wants to synchronize the complete sets they hold, this is completely sufficient. But more elaborate partitioning strategies can become attractive if nodes might wish to only synchronize certain subsets. The partitioning mechanism effectively dictates which such subsets can be described, taking on the role of a query language. A natural next step is to look for more powerful partitioning mechanisms that still admit efficient fingerprint computation.

We now give one such partitioning scheme by generalizing the one-dimensional ranges of the original presentation of the algorithm to $k$-dimensional ranges. Let $U$ be a finite set of items, and let $\preceq_0, \preceq_1, \ldots, \preceq_{k-1}$ be linear orders over $U$. A \defined{$k$-dimensional range} is a $k$-tuple $((x_0, y_0), (x_1, y_1), \ldots, (x_{k-1}, y_{k-1}))$ with $x_i \preceq_i y_i$. Given some $S \subseteq U$, the items from $S$ in this range are all items $v \in S$ such that $x_i \preceq_i v \preceq_i y_i$ for all $0 \leq i < k$. Note that for $k = 1$ this is equivalent to the ranges used in previous chapters. The reconciliation protocol needs to be adapted so that messages include the $k$-dimensional range boundaries, but otherwise no changes are required.

Fingerprints can be computed efficiently by storing the set as a (balanced) $k$-d tree~\cite{bentley1975multidimensional}. As $k$-d tree are binary trees, the labels from \cref{fingerprints} can be used without any modification. Fingerprint computation still works by traversing the tree, alternating between the dimensions just as in e.g. a $k$-d tree item lookup. For $k = 1$, this yields exactly the algorithms of \cref{fingerprints}.

Generalized partitioning schemes, including $k$-dimensional ranges, can not only be applied to the regular set reconciliation protocol, but also to all modifications discussed in the further sections.

\section{Map Reconciliation}
\label{maps}

A key-value mapping, i.e. a partial function $\partialfun{\m}{K}{V}$ with a finite domain from some set of keys $K$ to a set of values $V$, can be reconciled by reconciling the set $\set{(k, v) \mid \text{$k \in \domain(\m)$ and $v = \m(k)$}}$. After this reconciliation, a node may have obtained two pairs $(k, v), (k, v')$ if the two nodes mapped the same key $k$ to distinct values $v, v'$, so the resulting set would not correspond to an updated map. In those cases, both nodes compute the single new image of $k$ as $\f(v, v')$, where $\fun{\f}{V \times V}{V}$ is some function known to all participating nodes.

Particularly interesting are cases where $\f$ can be computed via another interactive protocol. If for example $V$ consists of the fingerprints of finite subsets of some universe $U$, and $\f(v, v')$ is defined to be the fingerprint of the union of the two sets whose fingerprints are $v$ and $v'$, then the two nodes can run a set reconciliation session to efficiently obtain the union. Viewn more abstractly, when reconciling a map, the values can be reconciled via arbitrary nested protocol invocations.

\section{Set and Map Mirroring}
\label{set-mirror}

We based the presentation of our synchronization approach on set reconciliation because it is a symmetric problem where both node use identical algorithms to compute identical types of messages. A related, asymmetric problem is that of a \defined{replica} node setting its locally stored set to that of a \defined{primary} node, utilizing similarity between the two initial sets to minimize the communication complexity. The approach of recursively exchanging fingerprints for subsets of decreasing size can be modified to solve this \defined{set mirroring} problem.

The primary node can run exactly the same protocol as that for such reconciliation. The replica node uses a slightly modified version. Whenever it receives a range item set, it adds the received items to its local set as usual, but then it deletes all item it holds within that range which were not part of the received range item set. Whenever the replica node sends a range item set, it sends an empty one.

The complexity analysis is identical to that of the set reconciliation protocol, the correctness argument is analogous: ranges with equal fingerprints are already correctly mirrored if no fingerprint collisions occurred, exchanging range item sets correctly mirrors all items within that range, and large ranges with non-equal fingerprints can be handled recursively because mirroring the partitions of a set results in mirroring the whole set.

Just as for reconciliation, maps can be mirrored by interpreting them as sets of key-value pairs. Mirroring maps has some interesting use cases, for example filesystems can be regarded as maps from paths to strings. The efficient creation of backups then becomes the problem of mirroring such a map onto a backup server that may already hold a similar, older backup. An equivalent problem is that of efficiently distributing source code updates from a server to clients which may hold old versions of the source code.

\section{Authenticated Data Structures}
\label{authenticated}

Authenticated data structures solve the problem of outsourcing data structure membership queries processing to untrusted replicas rather than processing all queries at the original trusted data source. The trusted source publishes a short digest to a client. The client can then send a query to a replica, which answers with the result and a small certificate which together with the digest proves that the answer is indeed correct. For more details on this three-party model and pointers to the rich literature on the topic, we refer to~\cite{martel2004general}.

Merkle trees form a simple authenticated set. The root label is the digest, and the certificate for an affirmative membership query consists of the labels of the children of the vertices on the path from the root to the item in question. These labels can be used to recompute the root label, proving that the item is part of the original tree. Fabricating a sequence of labels to fake inclusion of an item amounts to breaking the hash function. Non-membership queries can be authenticated by providing certificates for tree membership of items stored in adjacent leaves such that one is less than and one is greater than the item in question.

Our examination of randomized data structures was driven by the need for Merkle-like properties, so it is not very surprising that they can also be used as authenticated data structures. Indeed~\cite{naor2000certificate} mentions treaps as an alternative to regular Merkle trees. Monoidal labels based on Cayley hash functions remove the need for a specific tree shape to be maintained. Skip lists as authenticated data structures have been studied in~\cite{goodrich2000efficient}, but they require the hash function to be commutative. Our construction removes this assumption.
